"""OpenAI Agents SDK integration for LCTL.

Provides automatic tracing of OpenAI Agents SDK agent runs, tool calls,
and handoffs with LCTL for time-travel debugging.

Usage:
    from lctl.integrations.openai_agents import LCTLOpenAIAgentTracer

    tracer = LCTLOpenAIAgentTracer(chain_id="my-agent")

    # Use with Runner
    result = await Runner.run(agent, input="Hello", run_config=tracer.run_config)

    tracer.export("trace.lctl.json")
"""

from __future__ import annotations

import threading
import time
import uuid
from typing import Any, Dict, Optional

from ..core.session import LCTLSession
from .base import BaseTracer, truncate

try:
    from agents import (
        Agent,
        RunContextWrapper,
        RunHooks,
        Tool,
        Usage,
    )
    from agents.tracing import (
        Trace,
        TracingProcessor,
    )

    OPENAI_AGENTS_AVAILABLE = True
except ImportError:
    OPENAI_AGENTS_AVAILABLE = False
    Agent = None  # type: ignore[assignment, misc]
    RunContextWrapper = None  # type: ignore[assignment, misc]
    RunHooks = object  # type: ignore[assignment, misc]
    Tool = None  # type: ignore[assignment, misc]
    Usage = None  # type: ignore[assignment, misc]
    Trace = None  # type: ignore[assignment, misc]
    TracingProcessor = object  # type: ignore[assignment, misc]


# Default timeout for stale entry cleanup (1 hour)
DEFAULT_STALE_TIMEOUT_SECONDS: float = 3600.0


def _extract_usage(usage: Any) -> Dict[str, int]:
    """Extract token usage from Usage object."""
    tokens = {"input": 0, "output": 0}

    if usage is None:
        return tokens

    if hasattr(usage, "input_tokens"):
        tokens["input"] = usage.input_tokens or 0
    if hasattr(usage, "output_tokens"):
        tokens["output"] = usage.output_tokens or 0

    return tokens


class OpenAIAgentsNotAvailableError(ImportError):
    """Raised when OpenAI Agents SDK is not installed."""

    def __init__(self) -> None:
        super().__init__(
            "OpenAI Agents SDK is not installed. Install with: pip install openai-agents"
        )


def _check_openai_agents_available() -> None:
    """Check if OpenAI Agents SDK is available, raise error if not."""
    if not OPENAI_AGENTS_AVAILABLE:
        raise OpenAIAgentsNotAvailableError()


class LCTLRunHooks(RunHooks):
    """Run hooks implementation that records events to LCTL.

    Captures:
    - Agent run start/end
    - Tool calls
    - Handoffs between agents
    - Streaming events
    - Errors

    Thread-safe implementation with UUID-based tool tracking to prevent
    race conditions when multiple tools run concurrently.
    """

    def __init__(self, session: LCTLSession, verbose: bool = False) -> None:
        """Initialize the run hooks.

        Args:
            session: LCTL session for recording events.
            verbose: Enable verbose output.
        """
        self._session = session
        self._verbose = verbose
        self._run_stack: Dict[str, Dict[str, Any]] = {}
        self._tool_stack: Dict[str, Dict[str, Any]] = {}
        self._current_agent: Optional[str] = None
        self._lock = threading.Lock()
        self._tool_context_map: Dict[int, str] = {}

    def __repr__(self) -> str:
        """Return string representation for debugging."""
        with self._lock:
            return (
                f"LCTLRunHooks(session={self._session.chain.id!r}, "
                f"run_stack_size={len(self._run_stack)}, "
                f"tool_stack_size={len(self._tool_stack)}, "
                f"verbose={self._verbose})"
            )

    def _get_agent_name(self, agent: Any) -> str:
        """Extract agent name from agent object."""
        if agent is None:
            return "unknown"
        if hasattr(agent, "name") and agent.name:
            return str(agent.name)
        if hasattr(agent, "__class__"):
            return agent.__class__.__name__
        return "agent"

    def cleanup_stale_entries(self, max_age_seconds: float = DEFAULT_STALE_TIMEOUT_SECONDS) -> int:
        """Remove stale entries from run and tool stacks.

        Entries older than max_age_seconds are considered orphaned and removed.
        This helps prevent memory leaks from tools/runs that never completed.

        Args:
            max_age_seconds: Maximum age in seconds before an entry is considered stale.

        Returns:
            Number of entries removed.
        """
        current_time = time.time()
        removed_count = 0

        with self._lock:
            for stack in [self._run_stack, self._tool_stack]:
                stale_keys = [
                    k for k, v in stack.items()
                    if current_time - v.get("start_time", current_time) > max_age_seconds
                ]
                for k in stale_keys:
                    del stack[k]
                    removed_count += 1

            stale_context_keys = [
                k for k, v in self._tool_context_map.items()
                if v not in self._tool_stack
            ]
            for k in stale_context_keys:
                del self._tool_context_map[k]

        return removed_count

    async def on_agent_start(
        self,
        context: RunContextWrapper,
        agent: Agent,
    ) -> None:
        """Called when an agent starts execution."""
        try:
            agent_name = self._get_agent_name(agent)
            run_id = str(id(context))

            with self._lock:
                self._run_stack[run_id] = {
                    "agent": agent_name,
                    "start_time": time.time(),
                }
                self._current_agent = agent_name

            input_summary = ""
            if hasattr(context, "input") and context.input:
                input_text = str(context.input)
                input_summary = truncate(input_text)

            self._session.step_start(
                agent=agent_name,
                intent="agent_run",
                input_summary=input_summary,
            )

            if hasattr(agent, "instructions") and agent.instructions:
                self._session.add_fact(
                    fact_id=f"agent_{agent_name}_instructions",
                    text=f"Agent instructions: {truncate(agent.instructions, 300)}",
                    confidence=1.0,
                    source=agent_name,
                )

            if self._verbose:
                print(f"[LCTL] Agent started: {agent_name}")
        except Exception:
            pass

    async def on_agent_end(
        self,
        context: RunContextWrapper,
        agent: Agent,
        output: Any,
    ) -> None:
        """Called when an agent completes execution."""
        try:
            agent_name = self._get_agent_name(agent)
            run_id = str(id(context))

            with self._lock:
                run_info = self._run_stack.pop(run_id, {})
                self._current_agent = None

            start_time = run_info.get("start_time", time.time())
            duration_ms = int((time.time() - start_time) * 1000)

            output_summary = ""
            if output is not None:
                if hasattr(output, "final_output"):
                    output_summary = truncate(str(output.final_output))
                else:
                    output_summary = truncate(str(output))

            tokens = {"input": 0, "output": 0}
            if hasattr(output, "usage"):
                tokens = _extract_usage(output.usage)

            self._session.step_end(
                agent=agent_name,
                outcome="success",
                output_summary=output_summary,
                duration_ms=duration_ms,
                tokens_in=tokens["input"],
                tokens_out=tokens["output"],
            )

            if self._verbose:
                print(f"[LCTL] Agent ended: {agent_name} ({duration_ms}ms)")
        except Exception:
            pass

    async def on_tool_start(
        self,
        context: RunContextWrapper,
        agent: Agent,
        tool: Tool,
        input_data: Any,
    ) -> None:
        """Called when a tool invocation starts.

        Uses UUID-based tracking to prevent race conditions when multiple
        tools with the same name run concurrently.
        """
        try:
            tool_name = getattr(tool, "name", str(tool))
            tool_id = str(uuid.uuid4())
            context_id = id(context)

            with self._lock:
                self._tool_stack[tool_id] = {
                    "tool": tool_name,
                    "start_time": time.time(),
                    "input": input_data,
                    "tool_id": tool_id,
                }
                self._tool_context_map[context_id] = tool_id

            if self._verbose:
                agent_name = self._get_agent_name(agent)
                print(f"[LCTL] Tool started: {tool_name} (agent: {agent_name})")
        except Exception:
            pass

    async def on_tool_end(
        self,
        context: RunContextWrapper,
        agent: Agent,
        tool: Tool,
        output: Any,
    ) -> None:
        """Called when a tool invocation completes.

        Uses context-based UUID lookup for accurate tool matching.
        """
        try:
            tool_name = getattr(tool, "name", str(tool))
            context_id = id(context)

            with self._lock:
                tool_id = self._tool_context_map.pop(context_id, None)
                if tool_id is not None:
                    tool_info = self._tool_stack.pop(tool_id, None)
                else:
                    tool_info = None

            if tool_info is None:
                tool_info = {"tool": tool_name, "start_time": time.time(), "input": ""}

            start_time = tool_info.get("start_time", time.time())
            duration_ms = int((time.time() - start_time) * 1000)
            input_data = tool_info.get("input", "")

            input_str = truncate(str(input_data)) if input_data else ""
            output_str = truncate(str(output)) if output else ""

            self._session.tool_call(
                tool=tool_name,
                input_data=input_str,
                output_data=output_str,
                duration_ms=duration_ms,
            )

            if self._verbose:
                print(f"[LCTL] Tool ended: {tool_name} ({duration_ms}ms)")
        except Exception:
            pass

    async def on_tool_error(
        self,
        context: RunContextWrapper,
        agent: Agent,
        tool: Tool,
        error: BaseException,
    ) -> None:
        """Called when a tool invocation fails.

        Records both the tool call (with error output) and an error event.
        """
        try:
            tool_name = getattr(tool, "name", str(tool))
            context_id = id(context)

            with self._lock:
                tool_id = self._tool_context_map.pop(context_id, None)
                if tool_id is not None:
                    tool_info = self._tool_stack.pop(tool_id, None)
                else:
                    tool_info = None

            if tool_info is None:
                tool_info = {"tool": tool_name, "start_time": time.time(), "input": ""}

            start_time = tool_info.get("start_time", time.time())
            duration_ms = int((time.time() - start_time) * 1000)
            input_data = tool_info.get("input", "")

            input_str = truncate(str(input_data)) if input_data else ""
            error_output = f"ERROR: {type(error).__name__}: {str(error)[:100]}"

            self._session.tool_call(
                tool=tool_name,
                input_data=input_str,
                output_data=error_output,
                duration_ms=duration_ms,
            )

            self._session.error(
                category="tool_error",
                error_type=type(error).__name__,
                message=str(error),
                recoverable=True,
                suggested_action="Check tool input and retry",
            )

            if self._verbose:
                agent_name = self._get_agent_name(agent)
                print(f"[LCTL] Tool error: {tool_name} (agent: {agent_name}): {error}")
        except Exception:
            pass

    async def on_handoff(
        self,
        context: RunContextWrapper,
        from_agent: Agent,
        to_agent: Agent,
    ) -> None:
        """Called when control is handed off between agents."""
        try:
            from_name = self._get_agent_name(from_agent)
            to_name = self._get_agent_name(to_agent)

            self._session.add_fact(
                fact_id=f"handoff_{from_name}_to_{to_name}_{int(time.time() * 1000)}",
                text=f"Handoff from {from_name} to {to_name}",
                confidence=1.0,
                source=from_name,
            )

            if self._verbose:
                print(f"[LCTL] Handoff: {from_name} -> {to_name}")
        except Exception:
            pass

    async def on_error(
        self,
        context: RunContextWrapper,
        agent: Agent,
        error: BaseException,
    ) -> None:
        """Called when an error occurs during agent execution."""
        try:
            agent_name = self._get_agent_name(agent)
            run_id = str(id(context))

            with self._lock:
                run_info = self._run_stack.pop(run_id, {})

            start_time = run_info.get("start_time", time.time())
            duration_ms = int((time.time() - start_time) * 1000)

            self._session.step_end(
                agent=agent_name,
                outcome="error",
                output_summary=f"Error: {type(error).__name__}: {str(error)[:100]}",
                duration_ms=duration_ms,
            )

            self._session.error(
                category="agent_error",
                error_type=type(error).__name__,
                message=str(error),
                recoverable=False,
                suggested_action="Check agent configuration and input",
            )

            if self._verbose:
                print(f"[LCTL] Error in agent {agent_name}: {error}")
        except Exception:
            pass


class LCTLTracingProcessor(TracingProcessor):
    """Tracing processor that records traces to LCTL.

    This provides lower-level tracing that captures the full trace
    structure from the OpenAI Agents SDK.
    """

    def __init__(self, session: LCTLSession, verbose: bool = False) -> None:
        """Initialize the tracing processor.

        Args:
            session: LCTL session for recording events.
            verbose: Enable verbose output.
        """
        self._session = session
        self._verbose = verbose

    def __repr__(self) -> str:
        """Return string representation for debugging."""
        return (
            f"LCTLTracingProcessor(session={self._session.chain.id!r}, "
            f"verbose={self._verbose})"
        )

    def process_trace(self, trace: Trace) -> None:
        """Process a completed trace from the SDK."""
        try:
            if trace is None:
                return

            trace_data = {}
            if hasattr(trace, "to_dict"):
                trace_data = trace.to_dict()
            elif hasattr(trace, "__dict__"):
                trace_data = {
                    k: v for k, v in trace.__dict__.items()
                    if not k.startswith("_")
                }

            self._session.add_fact(
                fact_id=f"trace_{int(time.time() * 1000)}",
                text=f"Trace completed: {truncate(str(trace_data), 500)}",
                confidence=1.0,
                source="tracing_processor",
            )

            if self._verbose:
                print("[LCTL] Trace processed")
        except Exception:
            pass


class LCTLOpenAIAgentTracer(BaseTracer):
    """Main tracer class for OpenAI Agents SDK integration.

    Provides convenient methods to trace agent runs with LCTL,
    supporting both sync and async execution modes.

    Extends BaseTracer for standardized session management, thread safety,
    and automatic stale entry cleanup.

    Example:
        tracer = LCTLOpenAIAgentTracer(chain_id="my-agent")

        # Option 1: Use run_config with Runner
        result = await Runner.run(
            agent,
            input="Hello",
            run_config=tracer.run_config
        )

        # Option 2: Use hooks directly
        hooks = tracer.create_hooks()
        # Pass hooks to your runner configuration

        tracer.export("trace.lctl.json")
    """

    def __init__(
        self,
        chain_id: Optional[str] = None,
        session: Optional[LCTLSession] = None,
        verbose: bool = False,
        *,
        auto_cleanup: bool = True,
        cleanup_interval: float = 3600.0,
    ) -> None:
        """Initialize the OpenAI Agents SDK tracer.

        Args:
            chain_id: Optional chain ID for the LCTL session.
            session: Optional existing LCTL session to use.
            verbose: Enable verbose output.
            auto_cleanup: Whether to auto-cleanup stale entries.
            cleanup_interval: Cleanup interval in seconds (default 1 hour).
        """
        _check_openai_agents_available()

        super().__init__(
            chain_id=chain_id or f"openai-agent-{str(uuid.uuid4())[:8]}",
            session=session,
            auto_cleanup=auto_cleanup,
            cleanup_interval=cleanup_interval,
        )
        self._verbose = verbose
        self._hooks: Optional[LCTLRunHooks] = None
        self._tracing_processor: Optional[LCTLTracingProcessor] = None

    def __repr__(self) -> str:
        """Return string representation for debugging."""
        return (
            f"LCTLOpenAIAgentTracer(chain_id={self._session.chain.id!r}, "
            f"verbose={self._verbose})"
        )

    def create_hooks(self) -> LCTLRunHooks:
        """Create run hooks for the tracer.

        Returns:
            LCTLRunHooks instance configured with the session.
        """
        if self._hooks is None:
            self._hooks = LCTLRunHooks(self._session, verbose=self._verbose)
        return self._hooks

    def create_tracing_processor(self) -> LCTLTracingProcessor:
        """Create a tracing processor for the tracer.

        Returns:
            LCTLTracingProcessor instance configured with the session.
        """
        if self._tracing_processor is None:
            self._tracing_processor = LCTLTracingProcessor(
                self._session, verbose=self._verbose
            )
        return self._tracing_processor

    @property
    def run_config(self) -> Dict[str, Any]:
        """Get run configuration with LCTL hooks.

        Returns a configuration dictionary that can be passed to Runner.run().

        Returns:
            Dictionary with hooks configuration.
        """
        return {
            "hooks": self.create_hooks(),
        }

    def trace_agent_run(
        self,
        agent_name: str,
        input_summary: str = "",
    ) -> "AgentRunContext":
        """Context manager for manually tracing an agent run.

        Useful when you need more control over tracing or when
        using custom agent implementations.

        Args:
            agent_name: Name of the agent being traced.
            input_summary: Summary of the input to the agent.

        Returns:
            AgentRunContext that can be used as a context manager.

        Example:
            with tracer.trace_agent_run("my_agent", "Process data"):
                result = agent.process(data)
        """
        return AgentRunContext(
            self._session,
            agent_name,
            input_summary,
            verbose=self._verbose,
        )

    def record_tool_call(
        self,
        tool: str,
        input_data: Any,
        output_data: Any,
        duration_ms: int = 0,
    ) -> None:
        """Manually record a tool call.

        Args:
            tool: Name of the tool.
            input_data: Input to the tool.
            output_data: Output from the tool.
            duration_ms: Duration of the tool call in milliseconds.
        """
        self._session.tool_call(
            tool=tool,
            input_data=truncate(str(input_data)),
            output_data=truncate(str(output_data)),
            duration_ms=duration_ms,
        )

    def record_handoff(
        self,
        from_agent: str,
        to_agent: str,
    ) -> None:
        """Manually record an agent handoff.

        Args:
            from_agent: Name of the agent handing off.
            to_agent: Name of the agent receiving control.
        """
        self._session.add_fact(
            fact_id=f"handoff_{from_agent}_to_{to_agent}_{int(time.time() * 1000)}",
            text=f"Handoff from {from_agent} to {to_agent}",
            confidence=1.0,
            source=from_agent,
        )

    def record_error(
        self,
        agent_name: str,
        error: BaseException,
        recoverable: bool = False,
    ) -> None:
        """Manually record an error.

        Args:
            agent_name: Name of the agent where error occurred.
            error: The exception that was raised.
            recoverable: Whether the error is recoverable.
        """
        self._session.error(
            category="agent_error",
            error_type=type(error).__name__,
            message=str(error),
            recoverable=recoverable,
            suggested_action="Check agent configuration and input",
        )

    def export(self, path: str) -> None:
        """Export the LCTL trace to a file.

        Args:
            path: File path to export to (JSON or YAML).
        """
        super().export(path)
        if self._verbose:
            event_count = len(self.chain.events)
            print(f"[LCTL] Exported {event_count} events to {path}")


class AgentRunContext:
    """Context manager for tracing individual agent runs."""

    def __init__(
        self,
        session: LCTLSession,
        agent_name: str,
        input_summary: str = "",
        verbose: bool = False,
    ) -> None:
        """Initialize the agent run context.

        Args:
            session: LCTL session for recording events.
            agent_name: Name of the agent.
            input_summary: Summary of the input.
            verbose: Enable verbose output.
        """
        self._session = session
        self._agent_name = agent_name
        self._input_summary = input_summary
        self._verbose = verbose
        self._start_time: float = 0
        self._tokens_in: int = 0
        self._tokens_out: int = 0
        self._output_summary: str = ""

    def __repr__(self) -> str:
        """Return string representation for debugging."""
        return (
            f"AgentRunContext(agent_name={self._agent_name!r}, "
            f"input_summary={self._input_summary[:50]!r}...)"
        )

    def __enter__(self) -> "AgentRunContext":
        """Start tracing the agent run."""
        self._start_time = time.time()
        self._session.step_start(
            agent=self._agent_name,
            intent="agent_run",
            input_summary=self._input_summary,
        )
        if self._verbose:
            print(f"[LCTL] Agent run started: {self._agent_name}")
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        """End tracing the agent run."""
        duration_ms = int((time.time() - self._start_time) * 1000)

        if exc_type is not None:
            self._session.step_end(
                agent=self._agent_name,
                outcome="error",
                output_summary=f"Error: {exc_type.__name__}: {str(exc_val)[:100]}",
                duration_ms=duration_ms,
                tokens_in=self._tokens_in,
                tokens_out=self._tokens_out,
            )
            self._session.error(
                category="agent_error",
                error_type=exc_type.__name__,
                message=str(exc_val),
                recoverable=False,
            )
        else:
            self._session.step_end(
                agent=self._agent_name,
                outcome="success",
                output_summary=self._output_summary,
                duration_ms=duration_ms,
                tokens_in=self._tokens_in,
                tokens_out=self._tokens_out,
            )

        if self._verbose:
            status = "error" if exc_type else "success"
            print(f"[LCTL] Agent run ended: {self._agent_name} ({status}, {duration_ms}ms)")

        return False

    async def __aenter__(self) -> "AgentRunContext":
        """Async version of __enter__."""
        return self.__enter__()

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """Async version of __exit__."""
        return self.__exit__(exc_type, exc_val, exc_tb)

    def set_output(self, output_summary: str) -> None:
        """Set the output summary for the run.

        Args:
            output_summary: Summary of the output.
        """
        self._output_summary = truncate(output_summary)

    def set_usage(self, tokens_in: int = 0, tokens_out: int = 0) -> None:
        """Set token usage for the run.

        Args:
            tokens_in: Number of input tokens.
            tokens_out: Number of output tokens.
        """
        self._tokens_in = tokens_in
        self._tokens_out = tokens_out

    def record_tool_call(
        self,
        tool: str,
        input_data: Any,
        output_data: Any,
        duration_ms: int = 0,
    ) -> None:
        """Record a tool call within this run.

        Args:
            tool: Name of the tool.
            input_data: Input to the tool.
            output_data: Output from the tool.
            duration_ms: Duration of the tool call.
        """
        self._session.tool_call(
            tool=tool,
            input_data=truncate(str(input_data)),
            output_data=truncate(str(output_data)),
            duration_ms=duration_ms,
        )


def trace_agent(
    agent: "Agent",
    chain_id: Optional[str] = None,
    session: Optional[LCTLSession] = None,
    verbose: bool = False,
) -> "TracedAgent":
    """Wrap an OpenAI Agent with LCTL tracing.

    This returns a TracedAgent that automatically traces all runs.

    Args:
        agent: The OpenAI Agent to wrap.
        chain_id: Optional chain ID for the LCTL session.
        session: Optional existing LCTL session to use.
        verbose: Enable verbose output.

    Returns:
        TracedAgent wrapper with tracing enabled.

    Example:
        from agents import Agent
        from lctl.integrations.openai_agents import trace_agent

        agent = Agent(name="assistant", instructions="You are helpful")
        traced = trace_agent(agent, chain_id="my-agent")

        # Use traced.tracer to access LCTL functionality
        traced.tracer.export("trace.lctl.json")
    """
    _check_openai_agents_available()
    return TracedAgent(agent, chain_id=chain_id, session=session, verbose=verbose)


class TracedAgent:
    """Wrapper around an OpenAI Agent with LCTL tracing.

    Provides access to the underlying agent while maintaining
    a tracer for recording events.
    """

    __slots__ = ("_agent", "_tracer")

    def __init__(
        self,
        agent: "Agent",
        chain_id: Optional[str] = None,
        session: Optional[LCTLSession] = None,
        verbose: bool = False,
    ) -> None:
        """Initialize the traced agent.

        Args:
            agent: The OpenAI Agent to wrap.
            chain_id: Optional chain ID for the LCTL session.
            session: Optional existing LCTL session to use.
            verbose: Enable verbose output.
        """
        _check_openai_agents_available()

        object.__setattr__(self, "_agent", agent)
        object.__setattr__(
            self,
            "_tracer",
            LCTLOpenAIAgentTracer(
                chain_id=chain_id,
                session=session,
                verbose=verbose,
            ),
        )

        agent_name = getattr(agent, "name", "agent")
        if hasattr(agent, "instructions") and agent.instructions:
            self._tracer.session.add_fact(
                fact_id=f"agent_{agent_name}_config",
                text=f"Agent '{agent_name}' configured with instructions: {truncate(agent.instructions, 300)}",
                confidence=1.0,
                source="setup",
            )

    def __repr__(self) -> str:
        """Return string representation for debugging."""
        agent_name = getattr(self._agent, "name", "unknown")
        return (
            f"TracedAgent(agent_name={agent_name!r}, "
            f"chain_id={self._tracer.chain.id!r})"
        )

    @property
    def agent(self) -> "Agent":
        """Access the underlying OpenAI Agent."""
        return self._agent

    @property
    def tracer(self) -> LCTLOpenAIAgentTracer:
        """Access the LCTL tracer."""
        return self._tracer

    @property
    def run_config(self) -> Dict[str, Any]:
        """Get run configuration with LCTL hooks.

        Returns:
            Dictionary with hooks configuration.
        """
        return self._tracer.run_config

    def export(self, path: str) -> None:
        """Export the LCTL trace to a file.

        Args:
            path: File path to export to (JSON or YAML).
        """
        self._tracer.export(path)

    def to_dict(self) -> Dict[str, Any]:
        """Export the LCTL trace as a dictionary.

        Returns:
            The trace data as a dictionary.
        """
        return self._tracer.to_dict()

    def __getattr__(self, name: str) -> Any:
        """Proxy attribute access to the underlying agent.

        This method is only called when the attribute is not found
        on the TracedAgent instance itself. Uses object.__getattribute__
        to safely access _agent without infinite recursion.
        """
        try:
            agent = object.__getattribute__(self, "_agent")
            return getattr(agent, name)
        except AttributeError:
            raise AttributeError(
                f"'{type(self).__name__}' object has no attribute '{name}'"
            )


def is_available() -> bool:
    """Check if OpenAI Agents SDK integration is available.

    Returns:
        True if OpenAI Agents SDK is installed, False otherwise.
    """
    return OPENAI_AGENTS_AVAILABLE


__all__ = [
    "OPENAI_AGENTS_AVAILABLE",
    "OpenAIAgentsNotAvailableError",
    "LCTLRunHooks",
    "LCTLTracingProcessor",
    "LCTLOpenAIAgentTracer",
    "AgentRunContext",
    "TracedAgent",
    "trace_agent",
    "is_available",
]
